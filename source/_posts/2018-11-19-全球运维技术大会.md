---
title: 全球运维技术大会参会报告
author: 梅溪
comments: true
layout: post
slug: 
tags : [运维]
date: 2018-11-19 11:00:00
---



今日参加了全球运维技术大会。本文是参会作业。

https://cnutcon2018.geekbang.org/


![CNUTCON](/images/cnutcon.png)



##  听运维大会我听什么

我的关注点：

- 1)运维技术的整体态势；
- 2)业界其他公司在运维方面的组织架构；
- 3)具体技术比如监控、日志，容器环境等的技术选型。
- 4)大公司复杂系统的构建、部署过程。

二 运维技术的整体态势

听完两天的会议内容后我手绘一张图，展现了整体的趋势：




<img src="/images/mine.png" width="55%" height="55%">



### 所有产品都不可避免地走向平台化 
典型比如微博，从单体的php应用到如今的巨无霸，成为真正的大系统。

### 分布式+微服务的趋势

是几乎所有公司，在架构层面的共性主题。但是也带来新的问题。架构师的生命在于重(zhe)构(teng)。

### 基本都选择了kubernetes+docker 的交付、部署形态

对于复杂系统而言，这是业界大势，不可阻挡。

### 开源->商业->自研
非常多有技术能力的公司，在做系统的过程，都是经历了“开源”->”商业采购”->”自研”的过程。

- 早期没有能力自研也没有资金，用开源先上；
- 中期痛点问题开源解决不了，通过商业软件解决；
- 后期技术能力成熟后按自己需要开发定制。

### 运维技术栈，从做工具逐渐转变为智能化，数据化

AIOPS成为比较热门的概念。
在忙着鼓吹机器学习、人工智能之前，我们能看到，首先是把要把监控数据作为数据仓库建设起来，通过聚合、关联分析就能获得不少价值，比如减少告警，预测机器故障，针对应用、服务做画像等等。

### 监控系统，从忠实记录指标做告警，有了越来越多的定制化需求

比如：
- 同样的告警内容合并；告警可以加一些规则，规则可能会非常复杂；
- 告警之间需要存在关联。比如node的故障和node上所有的pod的故障是存在关联的，上报时可以予以汇集;
- 因为大型分布式应用的盛行，监控的重点，从底层的host指标，单体应用的指标更多向分布式trace的倾斜。


### 基础运维有新的挑战

主要涉及的资源除了传统的CPU/MEM/DISK/NETWORK之外，GPU也越来越重要。这其中最复杂的还是网络相关，但于此同时网络带宽却几乎已无人再关心（现代机房普遍万兆以上）。因为网络的复杂度不是所有公司都能cover，我看到一些公司甚至采取了看起来比较奇怪（但是可能更可控）的容器网络方案（比如斗鱼是给host分配特定ip网段来跑容器，所有容器都是静态IP无法迁移）。



## 运维组织架构


此处我最关心的是其他厂商如何定义运维相关的组织，包括人事和流程。



### 人事

新浪微博的同学提到他们的运维是分基础运维和产品运维。这一点很有启发。

所谓基础运维，是管跟业务相对关联不大的各种指标，比如管主机，管网络，看top，看cpu这些；
所谓产品运维，跟产品联系紧密，需求随产品特性产生，往往需要关注特定的指标数据，跟业务关联性较强。
对照我们产品线，以往运维，其实是各个产品研发眉毛胡子一把抓，可以参考一下新浪微博的做法：

- 1)基础运维，和具体产品无关，作为产品线基础人力资源库灵活调配。或者可以能力输出，交给一线人员和客户方面做（也比较适合现状）；
- 2)产品运维，一定是沉到具体产品项目里，按照DevOps倡议的组织结构开发测试运维人员一起做事，面向运维做开发，适应开发改进运维手段。


### 流程

参会多是互联网厂商，运维压力都是很大的。要保证7*24小时的响应，又不能照着一只羊薅毛，如何设计一套oncall的机制或者流程也是很关键的。

阿里云的某些部门做法是比较简单的轮流值班。这也是一种常见的做法。值班时别的工作没有办法交接，需要自己克服困难；

百度云会有一个告警系统，出现问题后首先以短信方式通知一级接口人，超时后改电话通知，再超时后通知二级接口人……以此类推。









## 部分技术选型参考



### 日志系统

当下最主流的，就是Filebeat + elasticsearch + kibana


### 监控系统



我们把整个监控系统分为采集--->存储--->展现三大部分。


- 其中展现部分选型比较趋同，就是Grafana。采集部分取决于存储系统，脚本，API，SQL方式都有。
- 最关键就是存储系统，常见的有Graphite，Prometheus，InfluxDB，Druid，OpenTSDB等。目前最常见的现在是InfluxDB（也是最新的一种）和Prometheus。
- 我们EMR用的还是ambari自带的监控系统，内置的是Phoenix/HBase方式。暂时够用，但是考虑到选型的一致性和长期可维护性，未来也许可逐步迁移到其他时序数据库。


从下表可以看到，各个监控存储系统其实同质化比较明显，InfluxDB更多胜在支持语言的丰富，资源占用的相对轻量。



![ske](/images/dbs.png)


比较特殊的一个是新浪微博广告，使用的是一种新开源的分布式数据库clickhouse，亮点在于性能和SQL语法的支持；
另一个是京东自研的监控系统，听完没有看到特别的亮点。






## CI/CD 持续集成，持续部署



这部分可能是我们跟先进公司差别最大的地方。


<img src="/images/cidi.png" width="55%" height="55%">

这是某公司分享的一张图。我们可以看到，

- 1)天为单位的上线时间，仍嫌太慢；
- 2)目标是简化运维，让开发自己可以简单发布。


![ske](/images/test.png)

这是eBay的分享，他们的测试工具本身已经是一个分布式的服务化的复杂系统。



包括：
- 1）所有工作流服务化；
- 2）测试环境的透明，易维护；
- 3）测试数据构造自动化标准化；
- 4）测试执行能力可扩展；
- 5）测试报告解析智能化(使用KNN自动分类)。

可以想见，这样复杂的系统对于开发能力要求是非常高的，但是带来的收益也是非常明显的。


六 总结

- 1)随着产品功能的细化，差异性愈大，运维能力沉淀入产品团队，跟着产品护航才是正确的；
- 2)技术选型越来越趋同。我们产品在运维方面的选型暂时没有什么明显的失误，其他各种技术也都了解到，照着用就好了，大体不差。但是日志、监控指标需要继续细化。基于微服务的比如服务发现，容错，trace等事情也可以逐步做起来，；
- 3)诸如CMDB这样的基本的运维基础设施做的不够好；
- 4)我们的问题级别定义，问题传导、响应和处理机制都还很不完善。运维有分级，问题有边界。要做到让一线和产品线基础运维人员能够直接解决基本的环境比如磁盘主板等硬件问题还有网络问题。但这个我们现在也还是没做到；
- 5)CI/CD是我们的最大短板。越是人少，就越应该多加重视。另外未来业界对测试的能力要求会越来越高，所有的领域所有的产品需要的都会是“通才”。
- 6)关于大会很热的AIOps概念。我的看法是先老老实实搜集好监控数据，做好“数仓”，做好运维数据的group by和join，就能解决不少问题。(下图调皮)


![ske](/images/ai.png)

