---
title: SparkSQL Adaptive Execution 简介
author: 梅溪
comments: true
layout: post
slug: 
tags : [大数据,spark]
date: 2018-12-25 09:55:00
---


#  SparkSQL Adaptive Execution 简介




Spark SQL 拥有友好的编程接口和卓越的性能，广受大数据处理从业者的欢迎。但是在典型的shuffle场景比如SQL Join场景中，Spark SQL仍然遭遇了不少性能和稳定性问题。

为此，社区和Intel/Baidu的同学先后两次提出了Adaptive Execution的修改议案。本博客将就相关修改做出说明。

两次修改的JIRA:


- https://issues.apache.org/jira/browse/SPARK-9850        2015年提出。
- https://issues.apache.org/jira/browse/SPARK-23128       2018年提出。


由于第一次的修改自从2016年后就没有实质进展，本文以第二次修改提案为准。

本文假设读者对Spark的基本运行原理已经有所了解。

## 当前存在的问题


我们先想一想，除了数据量大之外，Spark SQL处理数据的特点是什么呢？

<!--more-->

- 多是第一手数据。毕竟Spark往往是在做ETL，是数据加工的第一站；
- 数据来源丰富。一般是来自于Kafka，HDFS，Hive。也可能来自于HBase和RMDB。
- 迭代计算过程可以很复杂，也可能结合较多的业务相关UDF。


这些特点带来的问题是：

- 数据质量不高，容易有数据倾斜等问题；
- Spark本身不挑数据源，反过来讲，spark是从各种数据源加载数据，本身对于索引，数据分布状况等信息不敏感（虽然也有简单的CBO机制）；
- 数据经过处理后的输出情况可能很复杂，可能数据量比预期的小很多，也可能膨胀很多。

后两点带来的共同问题是：Spark在计算前难以准确估计加工后的数据大小，会给执行计划的优化带来很多困难。也就是说，虽然Spark SQL在map阶段读入数据时，还能够以一种相对还算的平均（大体平均，具体和文件数目大小相关）切分数据的方式划分任务集，但是一旦投入计算后，经历shuffle阶段时，就容易出现一些任务划分不合理或者说是性能上的瓶颈。

解决这些问题需要Spark SQL具备根据计算过程中的数据输出情况做动态调整，这就是AE的"Adaptive"的由来。下面我们就来看AE实际解决的具体问题。

## 问题一：  shuffle 分区不合理


Spark SQL在shuffle过程中的分区数目是通过spark.sql.shuffle.partitions来指定(不熟悉shuffle的同学可以简单理解为是把数据划分为固定个数的hash桶)，这种固定分区数目的做法会导致数据实际规模和任务并行度的不匹配：

- 数据量过大而分区数较少。造成单个任务处理数据量过多，一方面是并行度上不去，导致作业执行时间拉长。另一方面是带来较多的溢写，增加内存压力，容易出现FullGC，OOM等现象；
- 数据量过小而分区数较多。这显然是一种浪费，少数据量投入较多的任务，给调度侧(Spark driver)带来不必要的负担。而且考虑到数据最终落盘，较多分区意味着较多小文件，对HDFS等系统极不友好。



Spark提供了配置方式去调整shuffle分区数目（最新的spark 2.4甚至可以通过sql 语法中的hint 来调整），但是这个调整很难在生产中实际操作，因为很难明确该调成多少，哪怕今天通过反复执行调试好了，明天数据发生变化，情况可能又不一样了。

另外，一个复杂的Spark作业可能涉及非常多的stage，这个shuffle分区数目的调整可能只对某个stage是最优却并非全局最优。


AE提出了一种根据map stage执行后的数据大小和行数信息来自适应调整shuffle 分区数目的思路。


先看配置：

|Property Name |	Default	|Meaning|
|--------------|-----------|--------|
|spark.sql.adaptive.enabled|	false	|When true, enable adaptive query execution.|
|spark.sql.adaptive.minNumPostShufflePartitions	|1	|The minimum number of post-shuffle partitions used in adaptive execution. This can be used to control the minimum parallelism.|
|spark.sql.adaptive.maxNumPostShufflePartitions	|500|	The maximum number of post-shuffle partitions used in adaptive execution. This is also used as the initial shuffle partition number so please set it to an reasonable value.|
|spark.sql.adaptive.shuffle.targetPostShuffleInputSize	|67108864	|The target post-shuffle input size in bytes of a task. By default is 64 MB.|
|spark.sql.adaptive.shuffle.targetPostShuffleRowCount	|20000000	|The target post-shuffle row count of a task. This only takes effect if row count information is collected.|


配置参数很简单，使能后可以利用配置好的分区数，文件大小以及行数来控制shuffle分区数目，保证post-shuffle的任务处理的数据尽量均衡合理。


我们看看设计思路。


SPARK-9850 中的做法是首先增加底层API，为DAGScheduler增加submitMapStage()方法，接受代表给定map stage的ShuffleDependency，执行任务并返回一个MapOutputStatistics对象。


``` scala
    def submitMapStage[K, V, C](
        dependency: ShuffleDependency[K, V, C],
        callback: MapOutputStatistics => Unit,
        callSite: CallSite,
        properties: Properties): JobWaiter[MapOutputStatistics] = {
```



单独提交map stage，可以做到搜集到map stage的数据统计信息，便于后续规划stage的任务划分。


另外就是引入了一个结构ExchangeCoordinator用于指导stage之间数据shuffle的方式：

    A coordinator used to determines how we shuffle data between stages generated by Spark SQL.


ExchangeCoordinator 具体使用上是侵入原有的Exchange添加过程(EnsureRequirements，在prepareExecution这个phase)，根据具体情况把数据进行重分布，确保得到合理的分区数量。
实现上确实有一点丑陋，注释中，作者承认:

    Actually, it is not a good idea to add ExchangeCoordinators while we are adding Exchanges.

主要是因为并没有合适的地方能看到post-shuffle stage所有依赖的全景。


最核心逻辑是这样：


``` scala

children.zip(requiredChildDistributions).map {
          case (e: Exchange, _) =>
            // This child is an Exchange, we need to add the coordinator.
            e.copy(coordinator = Some(coordinator))
          case (child, distribution) =>            
            val targetPartitioning =
              createPartitioning(distribution, defaultNumPreShufflePartitions)
            assert(targetPartitioning.isInstanceOf[HashPartitioning])
            Exchange(targetPartitioning, child, Some(coordinator))

```            



 
SPARK-23128 对这种做法有质疑，提出三个问题:

- 会增加额外的shuffle阶段。注意看前面代码的第二个case，这种增加的Exchange很多情况可能是不必要的；
- 太机械。比如3表join，应该是三张表统一协同去exchange，而不是两两结合去exchange。 
- 无法扩充其他功能，比如修改执行计划，处理数据倾斜。


新的AE方案，和原先不同，没有基于比较底层的RDD来实现，而是在SQL 执行计划层面进行优化。增加新的节点类型QueryStage和QueryStageInput，一个执行计划会划分成多个QueryStage。
和之前方案最显著的差异就在于，更早的基于SQL 执行计划的规划，能够获得shuffle依赖的全貌。

- 能准确地和每一个实际涉及exchange的算子对应起来，避免额外增加exchange;
- 有全貌意味着能从更高的层面去统一优化、适应；
- 在执行计划层面的重构，意味着可以做更多的变化。

下面是一个简单的三表join的图例：

![Query plan for 3 tbl join](/images/queryplan.png)

具体可以看一下google doc： https://docs.google.com/document/d/1mpVjvQZRAkD-Ggy6-hcjXtBPiQoVbZGe3dLnAKgtJ4k/



一个栗子---启用了AE，每一个partition的大小分别是70MB，30MB，20MB，10MB和50MB，而配置的目标数据量是64M，最终的任务和数据分布参见下图：

![Adaptive Execution: reduce task number](/images/rtask_num.png)


## 问题二：（join）执行策略的优化


让我们考虑典型的join场景。

现在有两种基本的join策略： sort based join和broadcast join（也就是hive的map-side join）。前者可以理解为是把两张大表按照同样的hash规则（join的key）shuffle到不同的reduce任务去执行，后者是用于大小表join，把小表广播到各个task去做join，不涉及shuffle。显然，对于较小的表而言，采用后者能在性能上有不少的提升。



我们举个栗子：


比如100G和1张10M的表进行join，Map任务1000个（假如分布在50个node执行），reduce任务200个。

- 使用sort based的策略，shuffle总数据量约为100.01G, 单个reduce任务需要处理的数据量约为500M；
- 使用broadcast 的策略，完全不涉及shuffle，广播总数据量是500M，单个map任务处理数据量是110M。


我们从这个数量对比就可以感受到性能上的巨大差异。


Spark SQL 可以通过spark.sql.autoBroadcastJoinThreshold这个配置参数来控制选择BroadcastHashJoin的阈值，默认是10MB。但是这个只对直接map读入的数据有效，一旦涉及复杂的迭代计算，中间过程的数据是无法精确知道join中两边的实际大小的，也就没有机会采用本可以采用的broadcast join的策略。


下面直接抄一张图，join左侧的实际数据产出只有600k，但是执行计划没有动态修改能力，所以只能傻傻sort merged join。
![Broadcast fail](/images/broadcast_fail.png)


利用前面讲的，AE在运行时的map单独提交和Query Stage的整改，通过从shuffle依赖得到的输出信息，Spark 可以动态地选用BroadcastHashJoin。如下图所示：


![Adaptive Execution: join strategy](/images/ae-join.png)



配置也很简单：

| Property Name	|Default|	Meaning|
|--------------|-----------|--------|
| spark.sql.adaptive.join.enabled|	true|	When true and spark.sql.adaptive.enabled is enabled, a better join strategy is determined at runtime.|
|spark.sql.adaptiveBroadcastJoinThreshold|	equals to spark.sql.autoBroadcastJoinThreshold	|Configures the maximum size in bytes for a table that will be broadcast to all worker nodes when performing a join in adaptive exeuction mode. If not set, it equals to spark.sql.autoBroadcastJoinThreshold.|



## 问题三：数据倾斜


数据倾斜是Spark或者说大数据处理的常见问题。一般来说，分布式的数据处理系统都是靠数据分区来并行处理数据，对于Spark而言，一个数据分区对应一个task。在join等典型的处理场景里，按照join key来进行数据分区，而不同key的数据量差异往往会非常巨大，数据倾斜就是这种情况下特定分区的数据量远远超过其他分区的现象，带来的直接后果就是任务长尾（更恶劣的局面是最后一个任务在你苦等了许久之后因为OOM等各种原因失败，最终造成整个job的失败）。

数据倾斜令人苦恼，常见的处理手段有： 

- 预先过滤掉不合理的key值比如NULL，各种异常值等。这当然是一种好的做法，因为异常值的处理确实也没有意义。但是这种做法显然解决不了所有问题；
- 增加一些组合key值，把数据打的更散。这种方式也能解决问题，但是对业务侵入过重；
- 增加shuffle partition数量配置，可以投入更多reduce任务去执行，也就是hash桶更多。但是针对单个key的数据量过大的情况并不能解决问题；
- 部分场景强制使用broadcast hash join。这样的思路意味着做map side的join，不会出现相同key集中到特定少数的reduce task。但该方案需要有一张表足够小。



对数据倾斜的处理，我们先看AE 提供的配置：


|Property Name	| Default|	Meaning|
|--------------|-----------|--------|
|spark.sql.adaptive.skewedJoin.enabled |	false |	When true and spark.sql.adaptive.enabled is enabled, a skewed join is automatically handled at runtime.|
|spark.sql.adaptive.skewedPartitionFactor |	10|	A partition is considered as a skewed partition if its size is larger than this factor multiple the median partition size and also larger than spark.sql.adaptive.skewedPartitionSizeThreshold, or if its row count is larger than this factor multiple the median row count and also larger than spark.sql.adaptive.skewedPartitionRowCountThreshold.|
|spark.sql.adaptive.skewedPartitionSizeThreshold|	67108864|	Configures the minimum size in bytes for a partition that is considered as a skewed partition in adaptive skewed join.|
|spark.sql.adaptive.skewedPartitionRowCountThreshold|	10000000|	Configures the minimum row count for a partition that is considered as a skewed partition in adaptive skewed join.|
|spark.shuffle.statistics.verbose|	false|	Collect shuffle statistics in verbose mode, including row counts etc. This is required for handling skewed join.|




当AE启动后，Spark在运行时根据该stage每个mapper 的shuffle数据大小和记录条数进行检测，如果某一个partition的数据量或者记录条数超过中位数的N倍，并且大于某个预先配置的阈值，就判定为一个数据倾斜的partition，需要进行特殊的处理。对于倾斜的partition，不是采用1个task而是用多个task 去处理。


如下图，左右两侧A表B表进行join，A表的partition 0存在倾斜，AE执行时并不会把partition0 的数据全部交给一个task处理，而是用N个任务去处理之。同时这也意味着B表的相同key的分区需要复制给这N个task去处理（也就是有额外的针对B表对应分区的开销。假如B的分区0也存在倾斜，就需要也做拆分处理），最终数据集再union到一起。

![Adaptive Execution: skew](/images/ae-skew.png)




## TODO（永远不要相信程序员的TODO）： 我的测试实验结果




## 参考

https://issues.apache.org/jira/browse/SPARK-9850



https://github.com/Intel-bigdata/spark-adaptive

    